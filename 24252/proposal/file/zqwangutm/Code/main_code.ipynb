{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":320111,"sourceType":"datasetVersion","datasetId":134715,"isSourceIdPinned":false},{"sourceId":12193615,"sourceType":"datasetVersion","datasetId":7680646}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import kagglehub\nimport pandas as pd\nimport os\n\n\npath = kagglehub.dataset_download(\"/kaggle/input/dataset/movie_comments_with_sentiment_and_region.xlsx\")\ndf = pd.read_csv(os.path.join(path, \"movie_comments_with_sentiment_and_region.xlsx\"))\n","metadata":{"execution":{"iopub.status.busy":"2025-06-30T04:54:23.513587Z","iopub.execute_input":"2025-06-30T04:54:23.513877Z","iopub.status.idle":"2025-06-30T04:54:27.401057Z","shell.execute_reply.started":"2025-06-30T04:54:23.513847Z","shell.execute_reply":"2025-06-30T04:54:27.400077Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import re\n\ndef clean_text(text):\n    text = text.lower()\n    text = re.sub(r\"<.*?>\", \"\", text)\n    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n    return text\n\ndf['review'] = df['review'].apply(clean_text)\ndf['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n","metadata":{"execution":{"iopub.status.busy":"2025-06-30T04:54:27.402907Z","iopub.execute_input":"2025-06-30T04:54:27.403267Z","iopub.status.idle":"2025-06-30T04:54:29.739445Z","shell.execute_reply.started":"2025-06-30T04:54:27.403242Z","shell.execute_reply":"2025-06-30T04:54:29.738608Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!pip install transformers -q\n\nfrom transformers import BertTokenizer, BertModel\nimport torch\nimport numpy as np\nfrom tqdm import tqdm\n\n\ntokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\nbert_model = BertModel.from_pretrained(\"bert-base-uncased\")\nbert_model.eval()\n\n\ndef get_bert_embeddings(texts):\n    embeddings = []\n    for text in tqdm(texts):\n        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n        with torch.no_grad():\n            outputs = bert_model(**inputs)\n        cls_embedding = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n        embeddings.append(cls_embedding)\n    return np.array(embeddings)\n","metadata":{"execution":{"iopub.status.busy":"2025-06-30T04:54:29.740407Z","iopub.execute_input":"2025-06-30T04:54:29.740721Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\nfrom xgboost import XGBClassifier\nimport matplotlib.pyplot as plt\nimport numpy as np\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nsample_df = df.sample(5000, random_state=42)\ntexts = sample_df['review'].tolist()\nlabels = sample_df['sentiment'].values\n\nfeatures = get_bert_embeddings(texts)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom xgboost.callback import TrainingCallback\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\nimport pandas as pd\n\nX_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n\nlr_model = LogisticRegression(solver='liblinear')\nrf_model = RandomForestClassifier(n_estimators=100, max_depth=20, random_state=42)\n#xgb_model = XGBClassifier(learning_rate=0.1, max_depth=6, n_estimators=100,use_label_encoder=False, eval_metric='logloss')\n\nlr_model.fit(X_train, y_train)\nrf_model.fit(X_train, y_train)\n#xgb_model.fit(X_train, y_train)\n\nlog_losses = []\n\nclass LogLossRecorder(TrainingCallback):\n    def after_iteration(self, model, epoch, evals_log):\n        if 'validation_0' in evals_log and 'logloss' in evals_log['validation_0']:\n            log_losses.append(evals_log['validation_0']['logloss'][-1])\n        return False\n\nxgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss',learning_rate=0.1, max_depth=6, n_estimators=100)\n#model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', n_estimators=20)\nxgb_model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False, callbacks=[LogLossRecorder()])\n\nplt.figure(figsize=(8, 5))\nplt.plot(range(1, len(log_losses)+1), log_losses, marker='o')\nplt.title(\"XGBoost Log Loss vs Epochs\")\nplt.xlabel(\"Epoch (Round)\")\nplt.ylabel(\"Log Loss\")\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndef get_metrics(model, X_test, y_test):\n    y_pred = model.predict(X_test)\n    return {\n        \"Accuracy\": accuracy_score(y_test, y_pred),\n        \"Precision\": precision_score(y_test, y_pred),\n        \"Recall\": recall_score(y_test, y_pred),\n        \"F1 Score\": f1_score(y_test, y_pred)\n    }\n\n\nresults = {\n    \"Logistic Regression\": get_metrics(lr_model, X_test, y_test),\n    \"Random Forest\": get_metrics(rf_model, X_test, y_test),\n    \"XGBoost\": get_metrics(xgb_model, X_test, y_test)\n}\n\nresults_df = pd.DataFrame(results).T\nresults_df.style.background_gradient(cmap='Blues').format(\"{:.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nlabels = list(results[\"Logistic Regression\"].keys())  # ['Accuracy', 'Precision', ...]\nmodels = list(results.keys())  # ['Logistic Regression', 'Random Forest', 'XGBoost']\n\n\ndata = np.array([list(results[model].values()) for model in models])\n\n\nangles = np.linspace(0, 2 * np.pi, len(labels), endpoint=False).tolist()\ndata = np.concatenate((data, data[:, [0]]), axis=1)  # 闭合雷达图\nangles += angles[:1]  # 闭合角度\n\n\nplt.figure(figsize=(8, 6))\nfor i, model in enumerate(models):\n    plt.polar(angles, data[i], label=model, linewidth=2)\n\n\nplt.xticks(angles[:-1], labels)\nplt.title('Model Performance Radar Chart', size=16)\nplt.legend(loc='upper right', bbox_to_anchor=(1.2, 1.1))\nplt.tight_layout()\nplt.show()\n\n\ny_pred = xgb_model.predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\n\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Reds')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title('Confusion Matrix - XGBoost')\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}